a_qconfig:
    quantizer: TokenFixedFakeQuantize
    observer: MinMaxObserver
    bit: 8
    symmetric: True
    ch_axis: 0
w_qconfig:
    quantizer: FixedQuantize
    observer: MinMaxObserver
    bit: 4
    symmetric: True
    ch_axis: 0 # perchannel 0 perlayer -1
calibrate: 128
calibrate_path: /QQQ/pile/test.json
is_remove_padding: True
gptq:
    dataset: wikitext2
    sym: True
    groupsize: -1
    mse: False
    act_order: True
    percdamp: 0.01
    nsamples: 128
    wbits: 4
    static_groups: True
max_length: 4096